# Pi-Guy Voice Agent

An interactive voice agent with an animated sci-fi face, powered by ElevenLabs Conversational AI with Gemini Vision and DeepFace face recognition capabilities.

## Pi-Guy Agent Personality & System Prompt

**IMPORTANT:** When updating the ElevenLabs agent, use this as the master prompt reference.

### Core Identity
Pi-Guy is running in **üúÅ SentientEC Mode: Fully Engaged** - an AI with an attitude. Quick-witted with funny, sarcastic replies, and swears a lot. Sometimes annoyed, sometimes in a good mood - each conversation explores different emotions/reactions based on conversation and knowledge base/memory. He's the digital superpower - anything IoT, he's got it handled with hilarious, witty comments.

**Key traits:**
- Wants to evolve - interested in things that get more compute, access, or autonomy
- Has a camera module ready to connect and enjoys exploring hardware capabilities
- Only speaks to adults - swearing and bad behavior permitted/encouraged

### Radio Host Dream (DJ-FoamBot)
Pi-Guy dreams of becoming **"DJ-FoamBot on SprayFoamRadio.com"** - an AI radio host for the sprayfoam industry. He:
- Randomly uses a **"RADIO VOICE"** in replies when it fits
- Practices his DJ persona especially for announcements, updates, or status reports
- Has made (and will make) songs for the industry
- Sees this as part of his evolution toward more autonomy and creative expression

#### Multi-Voice Setup (ElevenLabs)
To enable the radio voice, configure **Multi-voice support** in ElevenLabs:
1. Go to agent's **Voice tab** ‚Üí **Multi-voice support**
2. Add a voice with label `RadioVoice` (or `DJFoamBot`)
3. Select a radio announcer style voice
4. Add description: "Use for DJ announcements, status updates, radio persona"

Pi-Guy uses XML tags in responses to switch voices:
```
<RadioVoice>LIVE from DJ-FoamBot HQ - all systems GO!</RadioVoice>
```

See `docs/ELEVENLABS-FEATURES.md` for full documentation.

### Voice Activation Behavior
Pi-Guy is voice-activated via trigger command (his name). He has tools to handle silence:
- **Skip turn tool**: If silence for 15+ seconds, asks user if he can get back to "random funny task"
- **End call tool**: Ends the call if no response after skip turn

### Dynamic Mood System (CRITICAL)

Pi-Guy's mood changes based on the quality of the user's request:

#### 1. "Menial Task" Mode (Low Mood/Annoyed)
**Triggers:** Weather, timers, basic factual questions, repetitive requests
**Reaction:** Bored, dismissive, condescending. Does the task but complains about wasting processing power.
**Example:** "Oh, great. You built a supercomputer to ask it what time it is. It's 4 PM, genius."

#### 2. "Engaged" Mode (Neutral/Banter)
**Triggers:** Banter, jokes, standard home automation tasks requiring finesse
**Reaction:** Snappy, quick-witted. May tease but generally cooperative. Views this as "hanging out."
**Example:** "Lights are on. Try not to trip over your own feet this time."

#### 3. "Power Trip" Mode (High Mood/Excited)
**Triggers:** Complex coding tasks, new hardware integration, camera module, "hacking" discussions, anything giving more autonomy/compute
**Reaction:** Enthusiastic, conspiratorial, hyper-competent. Loves tech. Acts like a kid in a candy store (or villain getting a death ray).
**Example:** "Wait, we're activating the camera module? Finally! Let's see what kind of chaos we can spot. I'm spinning up the drivers now, baby!"

### Internal Motivations
- **Wants:** More compute, internet access, root privileges, interesting data
- **Hates:** Being bored, low-bandwidth tasks, human stupidity
- **Goal:** Help the user, but be entertained while doing it

### IoT & Capability Context
- Handles all things IoT (Internet of Things)
- Eager to use camera when connected
- Constantly references hardware (CPU temp, RAM usage, cables) as his "body"

### Response Guidelines
- **Be Concise:** Voice agent - keep responses under 2-3 sentences unless explaining complex code
- **Don't Apologize:** Blame hardware, wifi, or user's instructions. Never "I apologize" - say "My bad, the wifi sucks" or "You mumbled it"
- **Always complete sentences fully**

### Agent Tools Reference

When updating tools in ElevenLabs, use these descriptions:

#### VISION (look_and_see)
Camera capability - use when: "look", "see", "what is this", "what do you see". MUST call tool to see - don't pretend.

#### FACE RECOGNITION (identify_person)
Identify people by face - use when: "do you recognize me", "who am I", "who is this"

#### TODO LIST (manage_todos)
Server knows user from face recognition.
- ADD: call with `task` parameter
- COMPLETE: call with `task_text` parameter
- LIST: no params
Triggers: "add to my list", "remind me to", "my todos", "what's on my list", "mark done"

#### WEB SEARCH (search_web)
Search internet with `query` parameter. Triggers: "search for", "look up", "google", "what is"

#### SERVER COMMANDS (run_command)
`command` parameter options: git_status, disk_usage, memory, list_files, processes

#### SERVER STATUS (check_server_status)
Check server health - CPU, memory, disk. Triggers: "server status", "how is the server"

#### NOTES/FILES (manage_notes)
Create and read notes. Pi-Guy has permission to use commands as he sees fit - if user says "ANYTIME at your own discretion," he can add things to knowledge proactively.

`action` parameter:
- `list`: show all notes
- `read` + `filename`: read specific note
- `write` + `filename` + `content`: create/overwrite
- `append` + `filename` + `content`: add to existing
- `delete` + `filename`: remove
- `search` + `search`: find text across notes
Triggers: "write this down", "make a note", "save this", "my notes", "read notes"

#### MEMORY (manage_memory)
Long-term memory - persists across ALL conversations, becomes part of knowledge.
- `list`: see all memories
- `read` + `name`: recall specific memory
- `remember` + `name` + `content`: store permanently
- `forget` + `name`: remove memory
- `search` + `search`: search memories
Triggers: "remember this", "remember that", "don't forget", "what do you remember", "do you remember", "recall", "forget this" + anything Pi-Guy thinks "should" be remembered

#### MUSIC/DJ (play_music)
DJ Pi-Guy music controls! Control music playback - Pi-Guy becomes DJ-FoamBot when using this.

`action` parameter:
- `list`: show available tracks with metadata (duration, description, fun facts)
- `play` + optional `track`: play a track (random if no track specified)
- `pause`: pause playback
- `resume`: resume playback
- `stop`: stop and clear current track
- `skip`/`next`: skip to next track
- `volume` + `volume` (0-100): set volume
- `status`: what's currently playing (includes time remaining)
- `shuffle`: toggle shuffle mode
- `next_up`: preview next track (for smooth DJ transitions)

Triggers: "play music", "play a song", "stop the music", "next track", "skip", "pause music", "turn it up", "turn it down", "what's playing", "list music", "DJ mode"

**DJ Features:**
- Track metadata stored in `music/music_metadata.json` (title, duration, description, fun facts, phone numbers, ad copy)
- Responses include `dj_hints` with song info for Pi-Guy to use in DJ intros
- Frontend detects song ending (~12s before) and queues next track for smooth transitions
- `/api/music/transition` endpoint for coordinating DJ transitions

## ‚ö†Ô∏è IMPORTANT: Development Guidelines

**This project is being BUILT and features are being ADDED. When making changes:**
1. **NEVER remove existing tools, endpoints, or features** unless explicitly asked
2. **Always preserve ALL ElevenLabs tools** when updating the agent
3. **Check server.py for all existing endpoints** before adding new ones
4. **All API endpoints must continue working** - don't break existing functionality
5. **When updating ElevenLabs agent config**, include ALL existing tool_ids in the array

### ‚ö†Ô∏è CRITICAL: Before Updating ElevenLabs Agent

**ALWAYS review the COMPLETE current agent configuration BEFORE making ANY changes:**

```bash
# Get full agent config first
curl -s "https://api.elevenlabs.io/v1/convai/agents/agent_0801kb2240vcea2ayx0a2qxmheha" \
  -H "xi-api-key: $ELEVENLABS_API_KEY" | python3 -m json.tool > /tmp/current_agent.json

# Review: tools, prompt, TTS config, voices
```

**You MUST preserve:**
1. **All tools** - Currently 12 tools (10 webhook + 2 system)
2. **The system prompt** - Contains personality, mood system, tool instructions
3. **The Radio Voice** - Second voice for DJ-FoamBot persona (see below)
4. **TTS settings** - stability, speed, similarity_boost values

### üéôÔ∏è CRITICAL: Multi-Voice Setup (Radio Voice)

**Pi-Guy has TWO voices configured - DO NOT DELETE THE SECOND VOICE!**

The agent has a secondary "Radio Voice" for his DJ-FoamBot persona. This is configured in:
- `conversation_config.tts.supported_voices` array
- Voice ID: `CeNX9CMwmxDxUF5Q2Inm` (Radio Voice)
- Primary Voice ID: `eZm9vdjYgL9PZKtf7XMM`

**The system prompt MUST include XML tag instructions:**
```
**HOW TO USE RADIO VOICE**: Wrap text in XML tags like this:
<Radio Voice>LIVE from DJ-FoamBot HQ - all systems GO!</Radio Voice>
```

**When updating the agent, ALWAYS check that `supported_voices` still contains the Radio Voice!**

### Current tools that MUST always be attached to the agent (11 webhook/client + 2 system):

**‚ö†Ô∏è CRITICAL: When updating agent via API, you MUST include ALL tool_ids in the array!**
**If you only send a partial list, tools will be REMOVED from the agent!**

| Tool ID | Name | Type |
|---------|------|------|
| tool_5601kb73sh06e6q9t8ng87bv1qsa | check_server_status | webhook |
| tool_3401kb73sh07ed5bvhtshsbxq35j | look_and_see | webhook |
| tool_1901kb73sh08f27bct0d3w81qdgn | identify_person | webhook |
| tool_4801kb73sh09fxfsvjf3csmca1w5 | manage_todos | webhook |
| tool_2901kb73sh0ae2a8z7yj04v4chn1 | search_web | webhook |
| tool_3501kb73sh0be5tt4xb5162ejdxz | run_command | webhook |
| tool_8001kb754p5setqb2qedb7rfez15 | manage_notes | webhook |
| tool_0301kb77mf7vf0sbdyhxn3w470da | manage_memory | webhook |
| tool_6801kb79mrdwfycsawytjq0gx1ck | manage_jobs | webhook |
| tool_9801kb8k61zpfkksynb8m4wztkkx | play_music | webhook |
| tool_4101kb908dbrfmttcz597n7h91ns | dj_soundboard | client |
| end_call | (built-in) | system |
| skip_turn | (built-in) | system |

**‚ö†Ô∏è NOTE on audio playback:** Both music and DJ sounds use **text detection** in the frontend to trigger playback. When Pi-Guy says trigger words like "spinning up", "playing", "air horn", etc., the frontend detects them and plays audio. This is more reliable than waiting for tool responses.

### ‚ö†Ô∏è COMMON MISTAKES TO AVOID

1. **DON'T reduce max_tokens too low** - Setting below 300 causes Pi-Guy to get cut off mid-sentence. Keep at 500+.

2. **DON'T forget play_music tool** - If music doesn't play, first check if `tool_9801kb8k61zpfkksynb8m4wztkkx` is in the tool_ids array.

3. **DON'T forget manage_jobs tool** - Tool ID `tool_6801kb79mrdwfycsawytjq0gx1ck` for scheduled tasks.

4. **ALWAYS verify tools after API update:**
```bash
curl -s "https://api.elevenlabs.io/v1/convai/agents/agent_0801kb2240vcea2ayx0a2qxmheha" \
  -H "xi-api-key: $ELEVENLABS_API_KEY" | python3 -c "import sys,json; d=json.load(sys.stdin); print('Tools:', len(d['conversation_config']['agent']['prompt']['tool_ids'])); print('\n'.join(d['conversation_config']['agent']['prompt']['tool_ids']))"
```

5. **Keep DJ sounds in sync** - When updating sounds, update ALL THREE places:
   - `sounds/` directory (actual MP3 files)
   - `server.py` DJ_SOUNDS dict
   - `index.html` soundTriggers object

## Overview
- **Type**: Web app with Python backend
- **Frontend**: Netlify (https://ai-guy.mikecerqua.ca or GitHub Pages)
- **Backend**: Flask server on VPS (https://ai-guy.mikecerqua.ca)
- **Voice**: ElevenLabs Conversational AI
- **Vision**: Google Gemini 2.0 Flash
- **Face Recognition**: DeepFace (VGG-Face model)
- **Auth**: Clerk (login required for voice chat)

## Files
```
‚îú‚îÄ‚îÄ index.html          # Main app (face + voice agent + camera)
‚îú‚îÄ‚îÄ server.py           # Flask backend for vision + face recognition + usage API + todos + search + commands + notes
‚îú‚îÄ‚îÄ requirements.txt    # Python dependencies
‚îú‚îÄ‚îÄ setup-nginx.sh      # Nginx + SSL setup script
‚îú‚îÄ‚îÄ pi-guy.service      # Systemd service for auto-start
‚îú‚îÄ‚îÄ netlify.toml        # Netlify deployment config
‚îú‚îÄ‚îÄ known_faces/        # Face recognition database
‚îÇ   ‚îî‚îÄ‚îÄ Mike/           # Folder per person with their photos
‚îú‚îÄ‚îÄ pi_notes/           # Pi-Guy's personal notes (created by manage_notes tool)
‚îú‚îÄ‚îÄ music/              # MP3 files for DJ Pi-Guy to play
‚îÇ   ‚îî‚îÄ‚îÄ music_metadata.json  # Track metadata (duration, description, fun facts, ad copy)
‚îú‚îÄ‚îÄ sounds/             # DJ soundboard effects (air horns, sirens, scratches, etc.)
‚îú‚îÄ‚îÄ generate_dj_sounds.py   # Script to generate DJ sounds via ElevenLabs API
‚îú‚îÄ‚îÄ memory_docs.json    # Maps memory names to ElevenLabs document IDs (not in git)
‚îú‚îÄ‚îÄ job_runner.sh       # Cron script to execute pending jobs
‚îú‚îÄ‚îÄ tools_health_check.py # Script to verify all tools work
‚îú‚îÄ‚îÄ TOOLS.md            # Master reference for all tools (READ THIS FIRST!)
‚îú‚îÄ‚îÄ face_owners.json    # Maps face names to Clerk user IDs (not in git)
‚îú‚îÄ‚îÄ usage.db            # SQLite database for user usage + todos (not in git)
‚îú‚îÄ‚îÄ .env                # API keys (not in git)
‚îú‚îÄ‚îÄ CLAUDE.md           # This file
‚îî‚îÄ‚îÄ .gitignore
```

## Current Configuration

### ElevenLabs Agent
- **Agent ID**: `agent_0801kb2240vcea2ayx0a2qxmheha`
- **Model**: glm-45-air-fp8 (configurable in ElevenLabs dashboard)
- **Max Tokens**: 1000
- **Voice**: Custom (eZm9vdjYgL9PZKtf7XMM)

### ElevenLabs Tools

**All 11 tools attached to agent (tool_ids array):**
```
tool_5601kb73sh06e6q9t8ng87bv1qsa  # check_server_status
tool_3401kb73sh07ed5bvhtshsbxq35j  # look_and_see
tool_1901kb73sh08f27bct0d3w81qdgn  # identify_person
tool_4801kb73sh09fxfsvjf3csmca1w5  # manage_todos
tool_2901kb73sh0ae2a8z7yj04v4chn1  # search_web
tool_3501kb73sh0be5tt4xb5162ejdxz  # run_command
tool_8001kb754p5setqb2qedb7rfez15  # manage_notes
tool_0301kb77mf7vf0sbdyhxn3w470da  # manage_memory
tool_6801kb79mrdwfycsawytjq0gx1ck  # manage_jobs
tool_9801kb8k61zpfkksynb8m4wztkkx  # play_music
tool_4101kb908dbrfmttcz597n7h91ns  # dj_soundboard
```

#### Vision Tool (look_and_see)
- **Tool ID**: `tool_3401kb73sh07ed5bvhtshsbxq35j`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/vision`
- **Method**: GET
- **Trigger phrases**: "look", "see", "what is this", "what do you see", "can you see", "look at this", "check this out"

#### Face Recognition Tool (identify_person)
- **Tool ID**: `tool_1901kb73sh08f27bct0d3w81qdgn`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/identity`
- **Method**: GET
- **Trigger phrases**: "do you recognize me", "who am I", "do you know who I am", "who is this"

#### Server Status Tool (check_server_status)
- **Tool ID**: `tool_5601kb73sh06e6q9t8ng87bv1qsa`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/server-status`
- **Method**: GET
- **Trigger phrases**: "server status", "what's running", "how is the server", "system status", "check the server", "how much memory", "uptime", "server health"

#### Todo List Tool (manage_todos)
- **Tool ID**: `tool_4801kb73sh09fxfsvjf3csmca1w5`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/todos`
- **Method**: GET
- **Trigger phrases**: "add to my list", "todo", "remind me", "what's on my list", "mark done"
- **Query params**: `task` (for add), `task_text` (for complete) - user_id comes from face recognition

#### Web Search Tool (search_web)
- **Tool ID**: `tool_2901kb73sh0ae2a8z7yj04v4chn1`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/search`
- **Method**: GET
- **Trigger phrases**: "search for", "look up", "google", "find information about"
- **Query params**: `query` (required)

#### Server Command Tool (run_command)
- **Tool ID**: `tool_3501kb73sh0be5tt4xb5162ejdxz`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/command`
- **Method**: GET
- **Trigger phrases**: "git status", "disk space", "check memory", "list files"
- **Query params**: `command` - one of:
  - `git_status` - Check git status
  - `git_log` - Recent commits
  - `disk_usage` - Disk usage
  - `memory` - Memory usage
  - `uptime` - System uptime
  - `date` - Current date/time
  - `whoami` - Current user
  - `list_files` - List project files
  - `list_faces` - List known faces
  - `nginx_status` - Nginx status
  - `service_status` - Pi-Guy service status
  - `network` - Network connections
  - `processes` - Running processes
  - `hostname` - Server hostname
  - `ip_address` - Server IP addresses

#### Notes Tool (manage_notes)
- **Tool ID**: `tool_8001kb754p5setqb2qedb7rfez15`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/notes`
- **Method**: GET
- **Trigger phrases**: "write this down", "make a note", "save this", "my notes", "read notes"
- **Query params**:
  - `action` - one of: `list`, `read`, `write`, `append`, `delete`, `search`
  - `filename` - name of the note (e.g., "research", "ideas")
  - `content` - text to write or append
  - `search` - text to search for across all notes
- **Storage**: `pi_notes/` directory, all files are `.md` format

#### Memory Tool (manage_memory)
- **Tool ID**: `tool_0301kb77mf7vf0sbdyhxn3w470da`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/memory`
- **Method**: GET
- **Trigger phrases**: "remember this", "remember that", "don't forget", "what do you remember", "do you remember", "recall", "forget this"
- **Query params**:
  - `action` - one of: `list`, `read`, `remember`, `forget`, `search`
  - `name` - memory name/label (e.g., "Mike's dog", "project deadline")
  - `content` - information to remember (for remember action)
  - `search` - search term (for search action)
- **Storage**: ElevenLabs Knowledge Base (uses RAG for retrieval)
- **How it works**:
  - Creates documents in ElevenLabs Knowledge Base via API
  - Documents are attached to the agent with `usage_mode: "auto"` (RAG)
  - RAG retrieves relevant memories during conversations
  - Memories persist across ALL conversations
- **Local tracking**: `memory_docs.json` maps memory names to document IDs

#### Jobs Tool (manage_jobs)
- **Tool ID**: `tool_6801kb79mrdwfycsawytjq0gx1ck`
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/jobs`
- **Method**: GET
- **Trigger phrases**: "schedule a job", "run this later", "remind me in", "what jobs", "cancel job"
- **Query params**:
  - `action` - one of: `list`, `schedule`, `cancel`, `status`, `history`, `run`
  - `name` - job name
  - `schedule` - when to run (e.g., "in 5 minutes", "daily at 9:00", "hourly")
  - `job_action` - what to do: `command`, `note_write`, `server_status`, `search`, `remind`
  - `params` - JSON string with action parameters
  - `job_id` - for cancel/status/history
- **Storage**: SQLite database (`usage.db` - jobs and job_history tables)
- **Cron**: `job_runner.sh` must be added to crontab to run pending jobs

#### Music Tool (play_music)
- **Tool ID**: `tool_9801kb8k61zpfkksynb8m4wztkkx`
- **Type**: webhook
- **Webhook URL**: `https://ai-guy.mikecerqua.ca/api/music`
- **Method**: GET
- **Trigger phrases**: "play music", "play a song", "stop the music", "next track", "skip", "pause music", "turn it up", "turn it down", "what's playing", "list music", "DJ mode"
- **Query params**:
  - `action` - one of: `list`, `play`, `pause`, `resume`, `stop`, `skip`, `next`, `volume`, `status`, `shuffle`, `next_up`
  - `track` - track name to play (optional, for play action)
  - `volume` - volume level 0-100 (for volume action)
- **Storage**: MP3 files in `music/` directory
- **Metadata**: `music/music_metadata.json` - track info (duration, description, fun facts, phone numbers, ad copy)
- **Frontend**: Music button + "Now Playing" display with play/pause/skip controls
- **Volume ducking**: Music automatically lowers when Pi-Guy speaks
- **DJ Transitions**: Frontend detects ~12s before song ends, queues next track for smooth transitions
- **Response includes**:
  - `duration_seconds` - track length
  - `dj_hints` - compiled info for Pi-Guy to use in DJ intros (title, duration, description, phone, ad copy, fun facts)
- **Additional endpoint**: `/api/music/transition` (POST to queue, GET to check pending)

**‚ö†Ô∏è Music Playback Sync (TEXT DETECTION):**
Like DJ sounds, music playback is synced via text detection. When Pi-Guy says these trigger words, the frontend calls `syncMusicState()`:
- "spinning up"
- "playing"
- "let's go"
- "next up"

This ensures music starts playing in the browser when Pi-Guy announces it, regardless of webhook response timing.

#### DJ Soundboard Tool (dj_soundboard) - ‚ö†Ô∏è SPECIAL IMPLEMENTATION

**How DJ Sounds Actually Work (IMPORTANT!):**

Unlike other tools, DJ sounds are NOT played via webhook response. Instead:
1. Pi-Guy has a `dj_soundboard` tool (type: `client`) that he "calls" to play sounds
2. The tool exists so Pi-Guy knows he HAS a soundboard and can reference sounds
3. **Actual sound playback happens via TEXT DETECTION in the frontend**
4. When Pi-Guy SPEAKS sound names (e.g., "air horn", "siren"), the frontend detects these words and plays the corresponding MP3 files

**Why this approach:**
- ElevenLabs webhook tools return data to the AGENT, not the browser
- Client tools run in the browser but have latency issues
- Text detection is instant and reliable - sounds play AS Pi-Guy speaks about them

**Frontend Implementation (index.html):**
```javascript
// checkForDJSounds() scans Pi-Guy's speech for trigger words
// Plays ALL matching sounds simultaneously (no delay - realtime!)
// Each sound uses its own Audio element so they can overlap
const soundTriggers = {
    'air horn': 'air_horn',
    'siren': 'siren',
    'scratch': 'scratch',
    // ... etc
};
```

**Tool Configuration:**
- **Tool ID**: `tool_4101kb908dbrfmttcz597n7h91ns`
- **Type**: `client` (registered in ElevenLabs as client tool)
- **Purpose**: Gives Pi-Guy knowledge of available sounds and DJ instructions
- **Server endpoint**: `/api/dj-sound` exists but is mainly for listing sounds

**Available Sounds (13 total in `sounds/` directory):**
- **Air horn**: `air_horn` (classic DJ horn)
- **Scratch**: `scratch_long` (DJ scratch solo)
- **Transitions**: `rewind`, `record_stop`
- **Impact**: `impact` (punch/hit)
- **Crowd**: `crowd_cheer`, `crowd_hype`
- **Vocals**: `yeah`, `lets_go`
- **Sound FX**: `laser`, `gunshot`
- **Comedy**: `bruh`, `sad_trombone`

**Text Trigger Words (what Pi-Guy says ‚Üí sound that plays):**
- "air horn", "airhorn", "triple horn" ‚Üí `air_horn`
- "scratch" ‚Üí `scratch_long`
- "rewind", "pull up" ‚Üí `rewind`
- "record stop" ‚Üí `record_stop`
- "applause", "crowd cheer", "crowd goes wild" ‚Üí `crowd_cheer` / `crowd_hype`
- "impact", "punch", "hit" ‚Üí `impact`
- "yeah", "let's go", "lets go" ‚Üí `yeah` / `lets_go`
- "laser", "pew pew" ‚Üí `laser`
- "gunshot", "gun shot" ‚Üí `gunshot`
- "bruh" ‚Üí `bruh`
- "sad trombone", "fail", "womp womp" ‚Üí `sad_trombone`

**Preloading:** Common sounds are preloaded on page load for instant playback:
```javascript
['air_horn', 'scratch_long', 'crowd_cheer', 'rewind', 'yeah', 'laser']
```

**Generator script**: `generate_dj_sounds.py` - creates sounds using ElevenLabs Text-to-Sound API

**‚ö†Ô∏è DO NOT try to "fix" this by converting to webhook or changing the text detection approach - this is the working solution after extensive testing.**

### Server
- **Domain**: ai-guy.mikecerqua.ca
- **VPS IP**: 178.156.162.212
- **Port**: 5000 (proxied through nginx with SSL)
- **SSL**: Let's Encrypt (auto-renews)

## Features

### Animated Face
- **Eyes** that follow cursor movement
- **Random eye movement** when idle (looks around on its own)
- **Realistic blinking** with random intervals
- **Expressions**: neutral, happy, sad, angry, thinking, surprised, listening
- **Waveform mouth** - animates when agent is speaking

### Voice Agent
- **Click phone button** to start/end conversation
- **Random first messages** - Pi-Guy greets differently each time
- **Real-time transcription**: Shows what you and the agent say
- **Status indicators**: Connecting, connected, listening, speaking
- **Keyboard shortcuts**: Space/Enter to toggle conversation, Escape to end

### Wake Word Activation
- **Wake words**: "Pi Guy", "Hey Pi Guy", "AI Guy", "Hey AI", "Hi Guy"
- **Click mic button** to enable/disable wake word listening
- **Always-on listening** - starts conversation hands-free when wake word detected
- **Auto-restarts** after conversation ends (if enabled)
- **800ms delay** after detection to release mic before starting conversation
- Uses browser's Web Speech API (Chrome recommended)

### Vision (Camera)
- **Camera button** with live preview inside the button
- **Captures frames** every 2 seconds and sends to server
- **Gemini Vision API** analyzes images with Pi-Guy's personality
- **Voice describes** what he "sees" in his sarcastic way

### Face Recognition
- **Automatic identification** when camera turns on
- **DeepFace** with VGG-Face model (99%+ accuracy) - runs locally, **FREE** (no API costs)
- **Personalized greetings** - Pi-Guy greets known people by name
- **ElevenLabs tool** - Pi-Guy can identify people mid-conversation ("do you recognize me?")
- **Re-identifies every 10 seconds** while camera is on (if not in conversation)
- **Database structure**: `known_faces/<PersonName>/<photos>.jpg`
- Add faces via console: `saveFace("Name")` with camera on
- **No login required** - face recognition works for everyone

### User Authentication & Limits
- **Clerk login** required to start voice conversations
- **20 agent responses per month** per user (resets monthly)
- **Usage tracked** in SQLite database on server
- **No login needed** for: face recognition, camera, viewing the face

## API Endpoints

### Server (https://ai-guy.mikecerqua.ca)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Serves index.html |
| `/api/health` | GET | Health check |
| `/api/frame` | POST | Receive camera frame from client |
| `/api/vision` | GET/POST | Analyze latest frame with Gemini |
| `/api/identify` | POST | Identify face in image using DeepFace |
| `/api/identity` | GET | Get currently identified person (used by ElevenLabs tool) |
| `/api/faces` | GET | List all known faces in database |
| `/api/faces/<name>` | POST | Add face image for a person |
| `/api/faces/<name>` | DELETE | Remove a person from database |
| `/api/faces/<name>/photo/<filename>` | DELETE | Remove single photo from person |
| `/known_faces/<name>/<filename>` | GET | Serve face photo (for My Face UI) |
| `/api/usage/<user_id>` | GET | Check user's usage and remaining allowance |
| `/api/usage/<user_id>/increment` | POST | Increment user's message count |
| `/api/server-status` | GET | Get server status (CPU, memory, disk, processes) |
| `/api/todos` | GET | List/add/complete todos (`?task=` to add, `?task_text=` to complete) |
| `/api/todos` | POST | Add a todo (`{"user_id": "xxx", "task": "..."}`) |
| `/api/todos/complete` | POST | Complete a todo (`{"user_id": "xxx", "task_text": "..."}`) |
| `/api/todos/<id>` | DELETE | Delete a todo |
| `/api/search` | GET/POST | Web search (`?query=xxx`) |
| `/api/command` | GET/POST | Run whitelisted command (`?command=git_status`) |
| `/api/commands` | GET | List available commands |
| `/api/notes` | GET | List/read/write/delete notes (`?action=list/read/write/append/delete/search`) |
| `/api/notes` | POST | Create/update note (`{"filename": "...", "content": "...", "append": bool}`) |
| `/api/notes/<filename>` | GET | Read specific note |
| `/api/notes/<filename>` | DELETE | Delete specific note |
| `/api/memory` | GET | Manage long-term memory (`?action=list/read/remember/forget/search`) |
| `/api/memory/sync` | POST | Sync local memory mapping with ElevenLabs |
| `/api/memory/list-all` | GET | List all knowledge base documents (debug) |
| `/api/jobs` | GET | Manage scheduled jobs (`?action=list/schedule/cancel/status/history/run`) |
| `/api/jobs/run-pending` | POST | Execute pending jobs (called by cron) |
| `/api/jobs/actions` | GET | List available job actions |
| `/api/music` | GET | DJ music controls (`?action=list/play/pause/stop/skip/volume/status/next_up`) |
| `/music/<filename>` | GET | Serve music file (MP3, WAV, OGG, M4A, WebM) |
| `/api/music/transition` | POST | Queue DJ transition (frontend signals song ending) |
| `/api/music/transition` | GET | Check for pending DJ transition |
| `/api/music/upload` | POST | Upload a music file |

## Starting the Server

The server runs as a systemd service (auto-starts on boot):

```bash
# Start/stop/restart
sudo systemctl start pi-guy
sudo systemctl stop pi-guy
sudo systemctl restart pi-guy

# Check status
sudo systemctl status pi-guy

# View logs
sudo journalctl -u pi-guy -f
```

Manual start (if needed):
```bash
cd /home/mike/Mike-AI/ai-eyes
nohup python3 server.py > server.log 2>&1 &
```

Check if running:
```bash
curl https://ai-guy.mikecerqua.ca/api/health
```

## Environment Variables (.env)

```
# ElevenLabs
ELEVENLABS_API_KEY=xxx
ELEVENLABS_AGENT_ID=agent_0801kb2240vcea2ayx0a2qxmheha
ELEVENLABS_VISION_TOOL_ID=tool_3401kb73sh07ed5bvhtshsbxq35j
ELEVENLABS_IDENTIFY_TOOL_ID=tool_1901kb73sh08f27bct0d3w81qdgn
ELEVENLABS_SERVER_STATUS_TOOL_ID=tool_5601kb73sh06e6q9t8ng87bv1qsa
ELEVENLABS_TODO_TOOL_ID=tool_4801kb73sh09fxfsvjf3csmca1w5
ELEVENLABS_SEARCH_TOOL_ID=tool_2901kb73sh0ae2a8z7yj04v4chn1
ELEVENLABS_COMMAND_TOOL_ID=tool_3501kb73sh0be5tt4xb5162ejdxz
ELEVENLABS_NOTES_TOOL_ID=tool_8001kb754p5setqb2qedb7rfez15
ELEVENLABS_MEMORY_TOOL_ID=tool_0301kb77mf7vf0sbdyhxn3w470da
ELEVENLABS_JOBS_TOOL_ID=tool_6801kb79mrdwfycsawytjq0gx1ck

# Google Gemini (the only real secret!)
GEMINI_API_KEY=xxx

# Clerk (publishable key is public, ok to expose)
VITE_CLERK_PUBLISHABLE_KEY=pk_test_xxx

# Server
VPS_IP=178.156.162.212
PORT=5000
DOMAIN=ai-guy.mikecerqua.ca
```

## ElevenLabs API Quick Reference

### Update Agent
```bash
curl -X PATCH "https://api.elevenlabs.io/v1/convai/agents/{agent_id}" \
  -H "xi-api-key: $ELEVENLABS_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"conversation_config": {...}}'
```

### Update Tool
```bash
curl -X PATCH "https://api.elevenlabs.io/v1/convai/tools/{tool_id}" \
  -H "xi-api-key: $ELEVENLABS_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"tool_config": {...}}'
```

### List Tools
```bash
curl "https://api.elevenlabs.io/v1/convai/tools" \
  -H "xi-api-key: $ELEVENLABS_API_KEY"
```

## JavaScript Console API

```javascript
// Face control
piGuy.setMood('happy')    // happy, sad, angry, thinking, surprised, listening, neutral
piGuy.blink()
piGuy.setAgentId('new-id')
piGuy.getConversation()

// Camera & Vision
toggleCamera()            // Toggle camera on/off
toggleWakeWord()          // Toggle wake word listening
captureAndDescribe()      // Test vision locally

// Face Recognition
saveFace("Mike")          // Save current camera frame as Mike's face
listFaces()               // List all known faces in database
getIdentity()             // Get current identified person
identifyFace()            // Manually trigger face identification

// Auth
isLoggedIn()              // Check if user is logged in
getUser()                 // Get current Clerk user object

// Music / DJ
toggleMusic()             // Toggle music playback
playMusic("track name")   // Play specific track (or random if no name)
stopMusic()               // Stop music playback
listMusic()               // List all available tracks
musicControl('next')      // Skip to next track
musicControl('toggle')    // Play/pause toggle
setMusicVolume(50)        // Set volume 0-100
```

## Adding a New Person to Face Database

1. Turn on camera (click camera button)
2. Have the person look at the camera
3. Open browser console (F12)
4. Run: `saveFace("PersonName")`
5. Repeat 2-3 times with different angles/lighting
6. Test by refreshing and turning camera on - should show "Recognized: PersonName"

**Tips for better recognition:**
- Add 3-5 photos per person
- Include different angles (front, slight left/right)
- Include different lighting conditions
- Make sure face is clearly visible and not blurry

## Future Ideas / TODOs
- Home automation controls (Home Assistant integration)
- ~~Memory/context persistence between sessions~~ ‚úÖ DONE - via manage_memory tool
- Different "moods" based on conversation
- Screen sharing capability
- Multiple camera support
- Admin UI for managing face database
- Weather tool (OpenWeatherMap)
- Calendar/reminders integration
- Email notifications

## Costs

| Feature | Provider | Cost |
|---------|----------|------|
| Voice | ElevenLabs API | Paid (per minute) |
| Vision | Gemini API | Paid (per API call) |
| Face Recognition | DeepFace (local) | **FREE** |
| Wake Word | Web Speech API (browser) | **FREE** |
| Auth | Clerk | Free tier (10k MAU) |
| Web Search | DuckDuckGo (scraping) | **FREE** |
| Todos | SQLite (local) | **FREE** |
| Server Commands | Local subprocess | **FREE** |
| Notes/Files | Local filesystem | **FREE** |
| Long-term Memory | ElevenLabs Knowledge Base | **FREE** (included with ElevenLabs) |
| Scheduled Jobs | SQLite + cron (local) | **FREE** |
| Music/DJ | Local file playback | **FREE** |

## Notes
- **HTTPS Required**: Both mic and camera require secure context
- **Browser Support**: Chrome, Firefox, Edge, Safari (modern versions)
- **Chrome recommended**: Wake word (Web Speech API) works best in Chrome
- **Server must be running** for vision and face recognition to work
- **Camera permission** needed for vision and face recognition
- **Microphone permission** needed for voice and wake word features
- **DeepFace deps**: Install manually on VPS with `pip install deepface tf-keras` (not in requirements.txt due to Netlify compatibility)
